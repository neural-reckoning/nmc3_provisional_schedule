
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>A deep generative modelling approach to detect epileptogenic lesions</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 13:30");</script>
            /
            Track 2
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-29 13:30" data-end="2020-10-29 13:45">
                <a href='https://www.youtube.com/watch?v=hYBrHmw4tuU'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=hYBrHmw4tuU'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>A deep generative modelling approach to detect epileptogenic lesions</h1><h2>Bastian David (He/Him)</h2><h3>Leonie Henschel, German Center for Neurodegenerative Diseases (DZNE); Sailesh Conjeti, German Center for Neurodegenerative Diseases (DZNE); Fabiane Schuch, Department of Epileptology, University Hospital Bonn; Bernd Weber, Department of Epileptology, University Hospital Bonn; Elke Hatingen, Department of Neuroradiology, Goethe University Frankfurt; Christian Elger, Department of Epileptology, University Hospital Bonn; Martin Reuter, German Center for Neurodegenerative Diseases (DZNE), Martinos Center for Biomedical Imaging, Radiology, MGH / Harvard Medical School; Rainer Surges, Department of Epileptology, University Hospital Bonn; Theodor Rüber, Department of Epileptology, University Hospital Bonn, Epilepsy Center Frankfurt Rhine-Main, Department of Neurology, Goethe University Frankfurt, Center for Personalized Translational Epilepsy Research (CePTER), Goethe- University Frankfurt</h3><h2>Abstract</h1><p>Purpose: Focal cortical dysplasias (FCDs) may be easily overlooked in conventional visual assessment of MRI. Automated approaches have been proven useful for the detection of FCDs and their use may enhance the postoperative outcome. However, as even most elaborate approaches do not yield satisfactory sensitivity, the development of novel approaches is warranted on clinical grounds. MRI features of FCD type IIb include cortical T2-signal hyperintensities but have sparse correlates in T1-weighted MR-volumes. We here describe an approach leveraging on this apparent difference in MR-modalities and the power of conditional generative adversarial networks (cGAN) in modality synthesis, by creating a difference image between the real FLAIR and a T1-based synthetic FLAIR mimicking healthy brain structures. We show that the integration of this information in a convolutional neural network (CNN) supports the automatized detection of FCDs.<br/><br/>Methods: We retrospectively collected and manually labelled T1w and FLAIR images of 42 patients (18 females; age=38.8±11.4 y) with an FCD type IIb. T1w images served as input for our cGAN, pre-trained on 80 datasets of healthy controls (37 females; age=44.8±10.6 y), to synthesize artificial FLAIR images. Real and synthetic FLAIR images were in turn subtracted. T1w, FLAIR and the difference images were passed to a multi-scale 3D CNN. Specificity was assessed on a separate cohort of 56 mesial temporal lobe epilepsy patients (35 females; age=39.2±11.5).<br/><br/>Results: The cGAN showed robust generation of synthetic FLAIR images on non-lesional brains (SSIM±σ = 0.92±0.04). Employing a five-fold cross-validation scheme, our CNN-classifier reached a sensitivity of 92.9% (39/42 FCDs detected), while maintaining a high specificity of 96.4% (54/56 true negatives).<br/><br/>Conclusion: Our combined deep learning approach using a cGAN for modality synthesis followed by a CNN outperforms current state-of-the-art methods. Moreover, it is conceivable that our approach may generalize to any other pathology imaged with complementary imaging modalities.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    