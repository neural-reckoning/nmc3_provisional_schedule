
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>LiftPose3D, a deep learning-based approach for transforming 2D to 3D pose in laboratory animals</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-26 21:15");</script>
            /
            Track 2
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-26 21:15" data-end="2020-10-26 21:30">
                <a href='https://www.youtube.com/watch?v=6UzkdlYH4MQ'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=6UzkdlYH4MQ'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>LiftPose3D, a deep learning-based approach for transforming 2D to 3D pose in laboratory animals</h1><h2>Adam Gosztolai</h2><h3>Semih Gunel, École Polytechnique Fédérale de Lausanne; Marco Pietro Abrate, École Polytechnique Fédérale de Lausanne; Daniel Morales, École Polytechnique Fédérale de Lausanne; Victor Lobato Rios, École Polytechnique Fédérale de Lausanne; Helge Rhodin, University of British Columbia; Pascal Fua, École Polytechnique Fédérale de Lausanne; Pavan Ramdya, École Polytechnique Fédérale de Lausanne</h3><h2>Abstract</h1><p>Markerless 3D pose estimation has become an indispensable tool for kinematic studies of laboratory animals. Most current methods recover 3D pose by multi-view triangulation of deep network-based 2D pose estimates. However, triangulation requires multiple, synchronised cameras per keypoint and elaborate calibration protocols that hinder its widespread adoption in laboratory studies. Here, we describe LiftPose3D, a deep network-based method that overcomes these barriers by reconstructing 3D poses from a single 2D camera view. We illustrate LiftPose3D’s versatility by applying it to multiple experimental systems using flies, mice, and macaque monkeys and in circumstances where 3D triangulation is impractical or impossible. Thus, LiftPose3D permits high-quality 3D pose estimation in the absence of complex camera arrays, tedious calibration procedures, and despite occluded keypoints in freely behaving animals.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    