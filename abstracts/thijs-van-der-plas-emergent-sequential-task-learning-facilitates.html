
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Emergent Sequential Task Learning Facilitates Convergence in Recurrent Neural Networks</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-30 12:00");</script>
            /
            Track 4
            /
            Interactive talk
        </h3>
        <h1>Emergent Sequential Task Learning Facilitates Convergence in Recurrent Neural Networks</h1><h2>Thijs van der Plas</h2><h3>Sanjay Manohar, University of Oxford; Tim Vogels, IST Vienna;</h3><h2>Abstract</h1><p>Neuronal networks can learn to maintain stimulus information in order to solve working memory tasks. Here, tasks are defined by their loss function that is optimised to solve the task. Loss functions can vary in difficulty, and various machine learning strategies have been developed to catalyse learning, such as drop-out, adaptive learning rates and various gradient descent methods. But these are all technical improvements of the involved algorithms, and do not inform us of how animal learning might be improved. Instead, we have identified a different, non-trivial strategy to improve learning, by adding a second, easier task to the loss function. Our original task requires a recurrent neural network to report the trial type at the end of each trial, by accumulating information throughout the trial. This is a difficult task to learn, and networks often fail to converge. This changes when an additional component is added to the loss function that requires networks to make short-term predictions throughout the trial, thus informing them of the trial structure. Networks emerge to learn to solve the second task first, thereby changing the functional profile of their neurons, after which they also learn to minimise the first component of the loss function. This unsupervised, sequential learning behaviour provides a new perspective on task optimisation. It shows that networks can decompose a loss function and learn its parts in an optimal sequence. This principle could potentially be applied to other difficult tasks, arguing that they may be solved by using additional, easier tasks, serving as a warm start to the network.</p>
    </body>
    </html>
    