
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>The role of frontal cortex in multisensory decision-making</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-27 13:30");</script>
            /
            Track 7
            /
            Traditional talk
        </h3>
        <h1>The role of frontal cortex in multisensory decision-making</h1><h2>Philip Coen</h2><h3>Philip Coen, University College London; Timothy P. Sit, University College London; Miles J. Wells, University College London; Matteo Carandini, University College London; Kenneth D. Harris, University College London</h3><h2>Abstract</h1><p>The ability to combine visual and auditory cues to localize objects in space is critical to many organisms, whether prey, predator, or pedestrian crossing the street. Recent studies have shown that the mouse frontal cortex plays a key role in transforming sensory stimuli into appropriate motor actions during decision-making tasks. However, real-world decisions are invariably multisensory. Where is the relevant multimodal information combined in the brain, and are separate modalities independently represented in frontal cortex?

To answer these questions, we trained mice to perform an audiovisual spatial task where animals turn a wheel to indicate whether a stimulus appeared on the left or right. The stimuli can be auditory, visual, or a combination of the two, presented in coherent or conflicting locations. We optogenetically inactivated different spots across dorsal cortex on individual trials while mice performed this task.

We found that auditory and visual primary sensory cortices were both required for the processing of modality-specific sensory information, and that the effect of inactivation in these regions was highly lateralized. Conversely, inactivation of secondary motor cortex (M2) had robust, modality-independent effects on behavior.

To determine whether frontal cortex contains separate representations of both modalities, or a modality-independent representation of the decision process, we recorded neural activity in M2 with Neuropixels probes in behaving mice. In preliminary analyses, we have observed a variety of response patterns, including neurons that are selective for both spatial location and stimulus modality. Overall, our results suggest a key role for M2 in multisensory decisions.</p>
    </body>
    </html>
    