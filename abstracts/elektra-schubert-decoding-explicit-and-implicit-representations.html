
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Decoding explicit and implicit representations of food health and taste attributes in the human brain </title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-28 01:30");</script>
            /
            Track 3
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-28 01:30" data-end="2020-10-28 01:45">
                <a href='https://www.youtube.com/watch?v=P6Y_-ojtvp8'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=P6Y_-ojtvp8'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Decoding explicit and implicit representations of food health and taste attributes in the human brain </h1><h2>Elektra Schubert</h2><h3>Elektra Schubert, University of Melbourne; Daniel Rosenblatt, University of Melbourne; Djamila Eliby, University of Melbourne; Yoshihisa Kashima, University of Melbourne; Hinze Hogendoorn, University of Melbourne; Stefan Bode, University of Melbourne</h3><h2>Abstract</h1><p>Visual food cues are constantly encountered in everyday life and are closely related to dietary decisions. The processing of these cues involves two key attributes: taste and health. This study aimed to examine whether and when these attributes are represented in the brain during the viewing of food images a) while making explicit health/taste judgements, and b) while implicitly considering food attributes for consumption decisions. We used multivariate support vector regression to determine whether spatiotemporal patterns of event-related potentials occurring in the first 1200 ms after the presentation of a food image could predict ratings of tastiness and healthiness on a trial-by-trial basis. In Experiment 1, participants (N = 37) were directly instructed to rate the tastiness and healthiness of various food items. The results showed that taste and health ratings could both be predicted significantly above chance, with taste (530-640 ms, 680-770 ms, 820-980 ms) becoming decodable slightly earlier than health (640-710 ms). In Experiment 2, a different sample of participants (N = 89) rated how strongly they would like to consume various food items, with no explicit instruction to consider tastiness or healthiness. Using the same analysis approach, we found that taste (740-1190 ms) and health (530-830ms) ratings could again be predicted significantly above chance. We could also predict the decision strength (830-920 ms), which might reflect the integration of taste and health information for decision-making. Taken together, our results suggest that taste and health information is decodable from electroencephalography data during dietary decisions, even when participants are not explicitly instructed to consider these attributes. This finding provides an exciting path for future studies to investigate potential alterations of taste and health representations following interventions, such as health warning messages, aimed at improving dietary choices.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    