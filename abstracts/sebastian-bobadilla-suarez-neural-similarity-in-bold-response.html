
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Neural similarity in BOLD response and multi-unit recordings</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-27 16:15");</script>
            /
            Track 6
            /
            Traditional talk
        </h3>
        <h1>Neural similarity in BOLD response and multi-unit recordings</h1><h2>Sebastian Bobadilla-Suarez</h2><h3>Marilena Lemonari, UCL; Scott L. Brincat, MIT; Markus Siegel, University of Tübingen; Earl K. Miller, MIT; Bradley C. Love, UCL and The Alan Turing Institute</h3><h2>Abstract</h1><p>One fundamental question is what makes two brain states similar. For example, what makes the activity in visual cortex elicited from viewing a robin similar to a sparrow? There are a number of possible ways to measure similarity, each of which makes certain conceptual commitments. In terms of information processing in the brain, interesting questions include whether notions of similarity are common across brain regions and tasks, as well as how attention can alter similarity representations. With multi-unit recordings, additional questions like the importance of spike timings can be considered. We evaluated which of several competing similarity measures best captured neural similarity. One technique uses a decoding approach to assess the information present in a brain region and the similarity measures that best correspond to the classifier’s confusion matrix are preferred. Across two published fMRI datasets, we found the preferred neural similarity measures were common across brain regions, but differed across tasks. In considering similarity spaces derived from monkey multi-unit recordings, we found that similarity measures that took into account spike timing information best recovered the representational spaces. In both fMRI and multi-unit data, we found that top-down attention, which highlighted task relevant stimulus attributes, had the effect of stretching neural representations along those axes to make stimuli differing on relevant attributes less similar. These effects were captured by a deep convolutional network front-end to a Long Short-Term Memory (LSTM) network that tracked changes in task context and whose representations stretched in a task-driven manner that paralleled patterns of neural similarity changed with task context.</p>
    </body>
    </html>
    