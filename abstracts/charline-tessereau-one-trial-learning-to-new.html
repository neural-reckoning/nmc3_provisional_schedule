
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>One-trial learning to new goal locations on a simulated delayed matching to place watermaze task by using minimal additions to an actor-critic architecture. </title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-27 09:30");</script>
            /
            Track 1
            /
            Traditional talk
        </h3>
        <h1>One-trial learning to new goal locations on a simulated delayed matching to place watermaze task by using minimal additions to an actor-critic architecture. </h1><h2>Charline Tessereau</h2><h3>Stephen Coombes, School of Mathematical Sciences, University of Nottingham; Reuben O'Dea,  School of Mathematical Sciences, University of Nottingham; Tobias Bast, School of psychology, University of Nottingham </h3><h2>Abstract</h1><p>Animals, including humans, are able to learn new spatial locations after a single visit [1,2,6]. This property, also termed one-shot learning, is challenging to capture in artificial agents in biologically realistic set-ups, and its underlying mechanisms are the focus of ongoing experimental and theoretical research. Here, we present an  approach to modelling spatial learning and navigation of an agent in a circular open field maze, using Temporal Difference (TD) learning within an actor-critic architecture (using a discrete action-space adapted from [3] and a continuous action-space adapted from [6] implemented via a rate, rather than spiking, framework) [7]. This architecture enables to map locations to actions to reach a fixed goal in the space, leading to behaviours close to the one of rats in the standard memory test of the Morris watermaze [3]. However, this agent requires many trials to adjust to changing goal locations, therefore failing to reproduce one-shot learning as observed in the watermaze delayed-matching-to-place (DMP) task [1,2,6]. We present two minimal additions which enable to adjust to changing goal locations. First, a map-like representation of locations is used to compute a vector-based direction to the goal [3]. Second, a meta-critic unit [5] which shapes the exploration of the agent and selects a successful policy for the current situation. We compare the behaviour of these agents to the behaviour of rats in the watermaze DMP task. 


[1] Bast, T., Wilson, I. A., Witter, M. P., and Morris, R. G. (2009). PLoS Biology.
[2] Buckley, M.G. and Bast, T., (2018). Hippocampus.
[3] Foster, D.J., Morris, R. G., and Dayan, P. (2000), Hippocampus.
[4] Fr√©maux, N., Sprekeler, H. and Gerstner, W. (2013). PLoS Computational Biology.
[5] Schweighofer, N., and Kenji D. (2003). Neural Networks.
[6] Steele, R.J. and Morris, R.G.M. (1999). Hippocampus.
[7] Tessereau, C., O'Dea, R., Coombes, S. and Bast, T. (2020). bioRxiv.
</p>
    </body>
    </html>
    