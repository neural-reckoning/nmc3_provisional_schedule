
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Preparatory eye movements reveal prior knowledge and intended interaction in VR</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-28 12:00");</script>
            /
            Track 1
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-28 12:00" data-end="2020-10-28 12:15">
                <a href='https://www.youtube.com/watch?v=WOlN8NwDRmk'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=WOlN8NwDRmk'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Preparatory eye movements reveal prior knowledge and intended interaction in VR</h1><h2>Ashima Keshava</h2><h3>Ashima Keshava; Nina Gottschewsky; Farbod Nosrat Nezami; Peter König</h3><h2>Abstract</h1><p>Most studies on human cognitive behavior are performed in controlled laboratory settings, limiting the validity and understanding of cognition in more naturalistic settings. The study of eye-movements in naturalistic tasks has revealed that the eyes precede the hands during an action. However, it is unclear how anticipatory and task-oriented eye movements are affected by prior knowledge about objects. The present study aims to investigate eye movement behavior while interacting with familiar and unfamiliar objects in a virtual environment. <br/>In this experiment, we study the gaze dynamics during interaction with 12 three-dimensional tool models in a virtual environment. We introduce a 2x2x2 factorial design with factors task, familiarity, and orientation. Participants were instructed to either lift or use a given familiar or unfamiliar tool. We presented the tools in two different orientations where the tool handle was presented either on the left or right side.<br/>We used linear mixed models, with a random slope and intercept for subject and stimulus items, to model the odds of fixations on the tool effector before grasp initiation based on task, familiarity, and orientation. The results suggest that subjects fixate more on the tool effector when the tool is unfamiliar and during the use task.  Also, during the lift task, fixations on the tool effector and handle were equally likely. Additionally, we did not find any effect of the orientation of the tool. <br/>These findings suggest that the given task and the available knowledge about an object influence a person’s gaze control strategy during object interaction. Finally, the effect of prior knowledge and task type in a naturalistic setting lends further evidence towards eye movements predominantly driven by higher-level cognitive functions.  <br/></p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    