
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>3D markerless tracking for human movement science</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 01:15");</script>
            /
            Track 5
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-29 01:15" data-end="2020-10-29 01:30">
                <a href='https://www.youtube.com/watch?v=I6F_sU1OPrQ'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=I6F_sU1OPrQ'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>3D markerless tracking for human movement science</h1><h2>Rachit Saluja</h2><h3>Rachit Saluja*, University of Pennsylvania; Nidhi Seethapathi*,  University of Pennsylvania; Konrad Kording, University of Pennsylvania;</h3><h2>Abstract</h1><p>Recent advances in computer vision have enabled tracking of 3D body pose in videos as they unfold over time. While movement science is quickly beginning to use 2D pose estimation, few studies use 3D computer vision algorithms with temporal tracking, in part because it is unclear which models would be appropriate for the movements that matter to movement science. Here, we compare state-of-the-art computer vision models on the types of movements (walking, running, reaching, jumping, interaction) and the types of metrics (3D velocity, acceleration, joint angles) important to movement science. We compare models that use different approaches such as GANs, sequence-to-sequence, heatmaps, and algebraic triangulation. Thus, we provide a pipeline for movement scientists to use these models on their video data and provide information necessary to choose between the models by testing them on the types of movements and metrics that are important for movement science.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    