
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Differences between representations shaped by supervised and unsupervised learning rules</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 20:15");</script>
            /
            Track 2
            /
            Interactive talk
        </h3>
        <h1>Differences between representations shaped by supervised and unsupervised learning rules</h1><h2>Ada Duan</h2><h3>Matthias Hennig</h3><h2>Abstract</h1><p>How the brain adjusts the synapses of individual neurons to support learning is an essential question in neuroscience. Backpropagation is the current most efficient solution for this problem in deep neural networks, and may be approximated by the brain to some extent. On the other hand, unsupervised learning rules like various forms of Hebbian learning are experimentally well supported, and are critical both during circuit development and learning from sensory information without supervision signals. The combination of supervised and unsupervised learning rules has therefore the potential to produce plasticity mechanisms that are both biologically plausible and can exploit their advantages. Here we study a learning rule combining backpropagation of gradients and an unsupervised Hebbian rule with competition between neurons, in a network receiving natural images as stimuli. The backpropagation objective is the image classification accuracy, while Hebbian learning causes emergence of typical visual receptive fields such as edge detectors, as well as less structured, random-looking kernels.  Results suggest while combined learning has similar classification performance with backpropagation alone, changes due to backpropagation may be small compared to changes of unsupervised learning. Structured receptive fields shaped by unsupervised learning result in a sparser contribution of neurons to correct prediction. When initialised from both random and structured kernels, random kernels tend to get more changes during backpropagation. Though unsupervised learned kernels seem to be slightly hindering the efficiency of backpropagation, they can better support transfer learning between classes. These suggest that top-down influences on early sensory receptive fields may generally be weak and experimentally hard to detect. The work is a first step in studying how to combine supervised and unsupervised learning rules to bring out respective advantages as well as learn in a more biologically plausible manner.</p>
    </body>
    </html>
    