
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Multi-animal pose estimation with DeepLabCut</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 13:15");</script>
            /
            Track 9
            /
            Interactive talk
            <div class="visible_at_time" data-start="2020-10-29 13:15" data-end="2020-10-29 13:30">
                <a href='https://www.youtube.com/watch?v=gX3I0xTpLLU'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=gX3I0xTpLLU'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Multi-animal pose estimation with DeepLabCut</h1><h2>Jessy Lauer (he/him)</h2><h3>Alexander Mathis, Swiss Federal Institute of Technology; Mackenzie Mathis, Swiss Federal Institute of Technology</h3><h2>Abstract</h1><p>Many experiments in biology require measuring interactions between multiple individuals. Nonetheless, whereas deep learning powered pose estimation recently showed remarkable performance on single animal, the solution to the multi-animal problem is far from trivial. Detected body parts must first be connected and associated with animals, which is a costly combinatorial task. Animalsâ€™ motion must then be tracked frame by frame, and the resulting trajectories stitched together to ensure dynamic feasibility and disambiguate overlaps and identity switches. Here we introduce DeepLabCut 2.2, a framework built onto the open-source pose estimation toolbox DeepLabCut to address the multi-animal scenario. We discuss our implementation of bottom-up animal assembly and robust motion trackers, as well as our novel solution to tracklet stitching and identity prediction directly from an image. We will demonstrate its utility on a collection of behaviors (from fish to mice). Taken together, DeepLabCut 2.2 thus provides users with an efficient solution to the multi-animal problem that is seamlessly integrated into the existing workflow and user interface, and requires just as little (if any) programming experience.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    