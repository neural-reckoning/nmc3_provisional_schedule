
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Comparison of Cortical Object Representation With Neuroscience-Inspired Deep Neural Networks</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-28 13:30");</script>
            /
            Track 4
            /
            Interactive talk
            <div class="visible_at_time" data-start="2020-10-28 13:30" data-end="2020-10-28 13:45">
                <a href='https://www.youtube.com/watch?v=SmdfsMa7bHM'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=SmdfsMa7bHM'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Comparison of Cortical Object Representation With Neuroscience-Inspired Deep Neural Networks</h1><h2>Niloufar Shahdoust</h2><h3>Mohammad-Reza A. Dehaqani, School of Electrical and Computer Engineering, University of Tehan, Tehran, Iran,   School of Cognitive Sciences, Institute for Research in Fundamental Sciences, Tehran, Iran; Babak N. Araabi, School of Electrical and Computer Engineering, University of Tehan, Tehran, Iran.</h3><h2>Abstract</h1><p>      Simulation of human visual perception stands out amongst the most important purposes of artificial intelligence. Artificial neural network, a computational model of biological neural network, is assumed as being highly inspired by human visual representation. Thus, understanding the cortical object representation would lead us to ameliorate deep neural network structures.<br/><br/>       Understanding the mechanisms of representation of objects in visual ventral pathway is achieved by analyzing the responses of neurons across temporal ventral stream. Layers of a deep neural network are claimed to resemble ventral pathway; theories posit that the DNN first layers and last layers are analogous to Retinal Ganglion Cells and Anterior Inferior Temporal respectively. <br/><br/>        The main focus of this study is comparison of stages of cortical object representation with neuroscience-inspired deep neural network layers with human object recognition performance. To this end, a dataset comprising of two groups of animate and inamitate line-drawings are divided into three groups: COMP, EDGE, and VERT. COMP group consist of intact line-drawing of animate and inamitate objects, while EDGE  and VERT groups are fragmented images of the same objects with only edge and vertex information respectively.  On one hand, the stimuli have been shown to sixteen 8 to 12 year-olds and they were asked to name the image for each of the three types. On the other hand, the stimuli were fed into a four layer CNN in order to compare their accuracies to human performance.<br/><br/>        The accuracy patterns of CNNs and human were exactly the same, whereas we expected them to have higher accuracies for CNNs on EDGE images. After visualizing representational dissimilarity matrix of images representations we concluded that, this similarity between human vision and modern computer vision is an inductive bias of DNNs.<br/><br/>Keywords: Visual Ventral Pathway; Biological Neural Network; Artificial Neural Network; Deep Neural Network; Cortical Visual Representation</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    