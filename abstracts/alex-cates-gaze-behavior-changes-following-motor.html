
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Gaze Behavior changes following motor learning in a gait training task</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 13:15");</script>
            /
            Track 6
            /
            Interactive talk
            <div class="visible_at_time" data-start="2020-10-29 13:15" data-end="2020-10-29 13:30">
                <a href='https://www.youtube.com/watch?v=M1TpiYsRvt0'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=M1TpiYsRvt0'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Gaze Behavior changes following motor learning in a gait training task</h1><h2>Alex Cates</h2><h3>Keith Gordon, Northwestern University</h3><h2>Abstract</h1><p>Vision plays a vital role in motor task execution and motor planning. During walking, where an individual looks and the distribution of their fixation locations provides insight into the preferred motor control strategies. Fixation distributions are well characterized in healthy adults and show consistent differences among individuals with gait deficits (who emphasize fixations involved in motor execution) and elite athletes (who emphasize fixations involved in motor planning). However, how individuals change their gaze distribution and the relationship to motor performance, is not understood. The present study examines how healthy young adults shift their gaze behavior during a locomotor learning task. Participants completed a treadmill-based sequence stepping task where they had to continuously step onto projected targets. The targets appeared in a repeating 6-step sequence of different step lengths which participants implicitly learned over multiple trial blocks. We hypothesized that participants would shift their gaze location forward (e.g. 2-3 steps ahead), emphasizing motor planning, as they learned the sequence. Our results did not support this hypothesis. With practice participants did learn the 6 step sequence and reduce their step error, however their gaze shifted closer to their feet, with participants spending more time fixating on the current target and immediate step path. This finding suggests that participants emphasized motor execution over motor planning while learning the task. Possible explanations for this result include a change in confidence, as awareness of their step errors may change step performance, or a change in information value, such that by learning the sequence, participants did not need visual information to plan their steps and could focus on optimizing stepping execution. Future studies should expand on these results with more complex stepping sequences, by artificially challenging participantsâ€™ confidence, and by disrupting visual informational value to see if gaze can be shifted in the opposite direction.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    