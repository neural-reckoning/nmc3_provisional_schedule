
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Towards optimal source reconstruction of resting MEG of the human brain: performance, precision, and parcellation</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-27 10:00");</script>
            /
            Track 6
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-27 10:00" data-end="2020-10-27 10:15">
                <a href='https://www.youtube.com/watch?v=GDV5heQOdUk'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=GDV5heQOdUk'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Towards optimal source reconstruction of resting MEG of the human brain: performance, precision, and parcellation</h1><h2>Luke Tait</h2><h3>Aysegul Ozkan; Maciej J Szul; Jiaxiang Zhang</h3><h2>Abstract</h1><p>Non-invasive functional neuroimaging of the human brain at rest can give crucial insight into the mechanisms that underpin healthy cognition and neurological disorders. Magnetoencephalography (MEG) measures extracranial magnetic fields originating from of neuronal activity with very high temporal resolution, but requires source reconstruction to make neuroanatomical inferences from these signals. Many source reconstruction algorithms for task-based MEG data are available. However, no consensus yet exists on the optimum algorithm for resting-state data.<br/><br/>Here, we evaluated the performance of six commonly-used source reconstruction algorithms based on minimum-norm and beamforming estimates. In the context of human resting-state MEG, we compared the algorithms using quantitative metrics, including resolution properties of inverse solutions and explained variance in sensor-level data. Next, we proposed a data-driven approach to reduce the atlas from the Human Connectome Project's multi-modal parcellation of the human cortex. This procedure produced a reduced cortical atlas with 230 regions, optimized to match the spatial resolution and the rank of MEG data from the current generation of MEG scanners.<br/><br/>Our results show that there is no `one size fits all' algorithm, and make recommendations on the appropriate algorithms depending on the data and aimed analyses. Our comprehensive comparisons and recommendations can serve as a guide for choosing appropriate methodologies in future studies of resting-state MEG.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    