
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>New ways to analyze and visualize large-scale network activity in sea slugs with single-neuron, single-spike resolution</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 18:15");</script>
            /
            Track 3
            /
            Interactive talk
            <div class="visible_at_time" data-start="2020-10-29 18:15" data-end="2020-10-29 18:30">
                <a href='https://www.youtube.com/watch?v=FaMMQK8ub0s'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=FaMMQK8ub0s'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>New ways to analyze and visualize large-scale network activity in sea slugs with single-neuron, single-spike resolution</h1><h2>Viral Mistry</h2><h3>Jeffrey Brown, RFUMS; Evan Hill, RFUMS; William Frost, RFUMS</h3><h2>Abstract</h1><p>Despite an ever-growing body of research elucidating how neural networks produce behavior, the contributions of specific neurons within those networks are often poorly understood. In particular, achieving both the temporal and spatial resolution in activity recordings of neuronal populations required to develop detailed bottom-up insights about how behavior is generated has proven to be a challenge for network neuroscience. Simple nervous systems, like those of gastropod mollusks, comprise relatively few, large, mostly superficial and individually identifiable neurons. This enables both electrophysiological and optical recordings with single-neuron, single-spike specificity over significant portions of those nervous systems, allowing for more thorough neuroethological investigation. Here, we discuss several computational tools we have recently developed to visualize and animate optical data collected in the brains of gastropod mollusks as a part of a BRAIN Initiative project taking a multi-dimensional approach to understanding how networks produce behavior. Large-scale optical recordings are obtained of motor programs of interest, using a photodiode array imaging at 1,600 samples/s and a fast-absorbance voltage-sensitive dye. These signals are then blind source separated into individual neuronal activity traces using independent component analysis. A custom algorithm maps the individual neuronal signals onto their source neurons in the recorded brain region, and then animates these maps to generate audiovisual “playbacks” of network activity with high spatiotemporal resolution. Through the use of a previously developed unsupervised community detection algorithm, we can also derive the functional neuronal ensembles operating during behavioral programs. Together, these tools constitute an ultra-fast workflow that provides same-day insights about both single-cell activity and network organization in recorded brain regions. This approach is well-suited to exploring network function in little studied, nontransgenic species, such as we are currently doing with the nudibranch Berghia stephanieae.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    