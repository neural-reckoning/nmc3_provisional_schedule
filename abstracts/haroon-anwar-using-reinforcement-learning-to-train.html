
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Using reinforcement learning to train biophysically detailed models of visual-motor cortex to play Atari games</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-30 22:00");</script>
            /
            Track 3
            /
            Traditional talk
        </h3>
        <h1>Using reinforcement learning to train biophysically detailed models of visual-motor cortex to play Atari games</h1><h2>Haroon Anwar</h2><h3>Salvador Dura-Bernal, Nathan Kline Institute for Psychiatric Research, Orangeburg, NY, State University of New York Downstate, Brooklyn, NY; David D’Onofrio, Nathan Kline Institute for Psychiatric Research, Orangeburg, NY; William W. Lytton, State University of New York Downstate, Brooklyn, NY; Peter Lakatos, Nathan Kline Institute for Psychiatric Research, Orangeburg, NY, NYU Langone Medical Center New York, NY; Samuel A. Neymotin, Nathan Kline Institute for Psychiatric Research, Orangeburg, NY, NYU Langone Medical Center New York, NY</h3><h2>Abstract</h1><p>In this work, we built a biophysically detailed spiking neuronal network model and trained it to play the Atari game Pong using a reinforcement learning algorithm. We explicitly modeled visual areas receiving, relaying and encoding visual inputs from the game environment, and motor areas receiving inputs from visual areas and generating motor commands controlling the game. We deployed reward-based learning mechanisms to produce associations between visual and motor neuronal representations. We used compartmental models of both excitatory and inhibitory neurons interconnected via AMPA/NMDA (excitatory) or GABAA (inhibitory) synapses. Synaptic connection strengths were adjusted to reliably transmit information across visual areas. The neurons in the early visual area received topological inputs and relayed information across all subsequent visual areas in a topological manner encoding object location in the environment. Modeled direction selective neurons were driven by the direction of objects’ motion at their respective locations. In our motor cortex model, neurons associated with a particular motor action were grouped together and received inputs from all visual areas representing the dorsal pathway. For the game Pong, we used three populations of motor neurons, for generating move up, move down and stay commands. Synapses between visual and motor cortex were plastic, so that the connection strengths could be increased or decreased via reinforcement learning. Model-generated actions updated the environment and triggered reward or punishment signals. These signals drove reinforcement learning at the synapses between visual cortex and motor cortex by strengthening or weakening them so that the model effectively learned which actions to produce to maximize rewards in a given context. Here we demonstrate that biophysically detailed models of neuronal circuits can be trained to solve problems that have so far only been tackled using artificial neural networks. We are using our model to dissect microcircuit mechanisms underlying production of visual-motor behavior.</p>
    </body>
    </html>
    