
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Sensory thalamus, speech, and predictive coding </title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-30 13:30");</script>
            /
            Track 1
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-30 13:30" data-end="2020-10-30 13:45">
                <a href='https://www.youtube.com/watch?v=OBmtAVSWc08'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=OBmtAVSWc08'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Sensory thalamus, speech, and predictive coding </h1><h2>Katharina von Kriegstein</h2><h3>Glad Mihai, TU Dresden; Stefan Kiebel, TU Dresden; Robert Trampel, MPI-CBS Leipzig; Alejandro Tabas, TU Dresden</h3><h2>Abstract</h1><p>The auditory (medial geniculate body, MGB) and visual (lateral geniculate nucleus, LGN) thalami are key structures of sensory processing in the human brain. Several studies in humans indicate that task-related modulation of MGB and LGN is critical for auditory and visual speech recognition and is reduced in developmental dyslexia. These findings might be explained in a predictive coding framework, where predictions generated  in cerebral cortex are used to optimise the processing of auditory and visual speech in sensory thalami. However, to date it is unclear whether responses in sensory thalami and other subcortical sensory pathway nuclei can be explained by predictive coding or habituation to stimulus statistics. In a novel study, we used ultra-high resolution functional magnetic resonance imaging (fMRI) at 7 Tesla to adjudicate between these two possibilities in the human subcortical auditory pathway. To elicit prediction error, we introduced frequency variations in pure tone sequences and abstract rules that manipulated the predictability of the tones orthogonally to the stimulus statistics. Our results show that predictability entailed in abstract rules drive mesoscopic responses to tones in the medial geniculate bodies and the inferior colliculi of the human auditory pathway. The results provide first unambiguous evidence of predictive coding in a subcortical sensory pathway â€“ a mechanism that might be used during auditory and visual speech recognition. </p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    