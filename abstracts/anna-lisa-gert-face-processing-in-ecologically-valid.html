
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Face processing in ecologically valid scenes:  Characterizing fixation related ERPs under free-viewing conditions</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 13:30");</script>
            /
            Track 7
            /
            Interactive talk
            <div class="visible_at_time" data-start="2020-10-29 13:30" data-end="2020-10-29 13:45">
                <a href='https://www.youtube.com/watch?v=s-hyV60ecmc'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=s-hyV60ecmc'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Face processing in ecologically valid scenes:  Characterizing fixation related ERPs under free-viewing conditions</h1><h2>Anna Lisa Gert</h2><h3>Benedikt V. Ehinger, Stuttgart University; Silja Timm, Osnabrück University; Peter König*, Osnabrück University; Tim C. Kietzmann,  Donders Institute for Brain, Cognition and Behaviour</h3><h2>Abstract</h1><p>Classically, the physiological mechanisms of face perception are studied under restricted, lab-based conditions. Specifically, visual stimuli are passively presented, no eye movements are allowed, and the timing is under the control of the experimenter, not the participant. While this approach yields high experimental control over factors influencing the signal of interest, it lacks natural validity. Here, we investigate whether we can replicate the N170, a face-sensitive ERP observed in classic experiments, in a free-viewing paradigm using natural scenes.<br/>First, we use a passive control-condition to replicate the classical N170 findings. The same participants then view images taken from a head-camera in a local shopping center under free-viewing conditions. We model our data using the unfold toolbox, which also corrects for overlap effects and co-varying non-linear dependencies on different eye movement parameters. Additionally, we extend the analysis beyond classically electrode sites and time windows by employing TFCE.<br/>In the classic setup, we replicate the face-object N170 contrast. In the free-viewing condition, we find a similar effect, but additionally, the amplitude of the P100 is also increased when a face is fixated. Underlining the usefulness of the more natural free-viewing approach the N170 face-effect correlates between the passive and active condition (r=0.78), and the variability within the subjects is decreased under free-viewing conditions. Interestingly, when looking at fERPs assigned by the category of the previous fixation, we find more positive fERPs for fixations originating from a face, even before fixation onset. This indicates an adaptation effect when moving from one to the next fixation. This effect becomes even stronger for two consecutive fixations within a face.<br/><br/>In summary, we demonstrate the feasibility of an ecologically valid study of face processing, uncovering neural aspects previously remaining unnoticed. <br/></p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    