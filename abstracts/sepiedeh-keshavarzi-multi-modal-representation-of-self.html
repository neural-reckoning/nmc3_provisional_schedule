
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Multi-modal representation of self-motion in the retrosplenial cortex</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-30 12:30");</script>
            /
            Track 1
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-30 12:30" data-end="2020-10-30 12:45">
                <a href='https://www.youtube.com/watch?v=WOlN8NwDRmk'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=WOlN8NwDRmk'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Multi-modal representation of self-motion in the retrosplenial cortex</h1><h2>Sepiedeh Keshavarzi</h2><h3>Edward F Bracey, Sainsbury Wellcome Centre, UCL; Dario Campagner, Sainsbury Wellcome Centre, UCL; Adam L Tyson, Sainsbury Wellcome Centre, UCL; Stephen C Lenzi, Sainsbury Wellcome Centre, UCL; Tiago Branco, Sainsbury Wellcome Centre, UCL; Troy W Margrie, Sainsbury Wellcome Centre, UCL</h3><h2>Abstract</h1><p>Successful navigation depends on animalsâ€™ ability to reliably track their orientation and heading direction. The internal representation of such directional sense requires angular head velocity (AHV) information. However, despite numerous studies on head direction, place, and grid cells, little is known about the computations underlying AHV signalling, and in particular, how this is achieved in higher order cortical regions in the mammalian brain. Using high-density single-unit recordings, we describe the activity of AHV neurons in the retrosplenial cortex (RSP) of mice exploring a large arena, and in response to vestibular and visual motion stimuli under controlled head-fixed conditions. We find that many AHV neurons display similar tuning properties during active (freely moving) and passive motion (head-fixed rotations in yaw), and combine vestibular and visual inputs to increase the gain and signal-to-noise ratio of angular velocity coding during navigation. Further, using a novel go/no-go task and computational methods, we demonstrate that vestibular-visual combination increases the perceptual accuracy of own velocity, and the fidelity of its representation by RSP neuronal ensembles. These findings provide novel insights into cortical computations underlying representation of self-motion during navigation.<br/><br/></p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    