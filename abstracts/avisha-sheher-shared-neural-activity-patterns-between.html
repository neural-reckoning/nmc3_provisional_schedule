
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Shared neural activity patterns between facial expression and shape recognition</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-26 16:30");</script>
            /
            Track 4
            /
            Interactive talk
        </h3>
        <h1>Shared neural activity patterns between facial expression and shape recognition</h1><h2>Avisha She/Her</h2><h3>Abhinav Singh, Integrated Science Education And Research Centre (ISERC),â€© Visva-Bharati University, Santiniketan; Hardik Bhatnagar; Birla Institute of Technology and Science, Pilani; Alish Dipani, Birla Institute of Technology and Science, KK Birla Goa Campus; Anindita Bhattacharjee, Indian Institute of Technology, Banaras Hindu University; Nidhi Seethapathi, University of Pennsylvania</h3><h2>Abstract</h1><p>Facial expressions are among the most informative stimuli we perceive: Even a split-second impression of a person's face gives us an estimate of their mood and direction of attention. Existing neurological evidence strongly suggests the existence of machinery dedicated to processing facial expressions in the human brain. We consider an essential shape recognition process gates this facial expression processing machinery.
Therefore, here we propose a hypothesis that the facial expression recognition mechanism shares some shape recognition steps in the visual system in the cortical areas. We tested this hypothesis using the fMRI data from the Human Connectome Project of 339 subjects performing an emotion processing task. Similar to the Hariri emotion task paradigm, the subjects matched fearful or angry facial expressions with expressions on the bottom of the screen and also matched geometric shapes like longitudinal and latitudinal ellipses.  
We separately analysed BOLD activations of the cortical surface regions of the two tasks using Multi-variate pattern analysis. We first selected the top 5% most active brain regions for both the tasks using ANOVA feature selection. These selected features using support vector machines linear kernel classified facial expressions recognition from resting-state with an accuracy of 83%. Similarly, for shape recognition, we got 81% accuracy.  Further, the selected areas in ventral stream visual cortex like Posterior Inferior Temporal, Fusiform Face Complex, VMV3 in a ventromedial visual area, which best correlated with object recognition, showed a high correlation with facial expression recognition as well. The other cortical regions involving primary and early visual cortical sectors were also common to both the recognition tasks, but with varying degrees of activation. Thus, these results indicate that facial expression recognition and shape recognition have shared neural activity patterns. 
</p>
    </body>
    </html>
    