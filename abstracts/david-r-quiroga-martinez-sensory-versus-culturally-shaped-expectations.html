
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Sensory versus culturally shaped expectations in the neural processing of music</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	}
    
        </script>
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-30 13:00");</script>
            /
            Track 1
            /
            Traditional talk
        </h3>
        <h1>Sensory versus culturally shaped expectations in the neural processing of music</h1><h2>David R. Quiroga-Martinez</h2><h3>Marina Kliuchko, Technical University of Denmark; Niels Chr. Hansen, Aarhus Institute of Advanced Studies & Center for Music in the Brain, Aarhus University, Denmark; Andreas HÃ¸jlund, Center for Functionally Integrative Neuroscience, Aarhus University, Denmark; Marcus Pearce, School of Electronic Engineering and Computer Science, Queen Mary University of London, UK; Elvira Brattico, Center for Music in the Brain, Aarhus University; Peter Vuust, Center for Music in the Brain, Aarhus University</h3><h2>Abstract</h1><p>When listening to music, we constantly attempt to predict the sounds that will follow. For example, quite often we end up humming, singing along or tapping our foot to the beat, and find pleasure in listening to pieces we know very well. However, the nature and brain basis of musical predictions or expectations remain poorly understood. Concretely, we do not know the extent to which these expectations arise from adaptation to the sensory properties of sounds or from a more cognitive and culturally shaped learning of the statistics of musical pieces and styles. In this presentation, I will address this issue by showing MEG data and modeling work in which the neural correlates of melodic expectations are investigated. I will show comparisons between the performance of a cognitive model of music statistical learning (IDyOM) and simpler metrics of acoustic similarity between tones (e.g. pitch distance, cosine similarity) in predicting neural responses to sounds. For this, an encoding model based on regularized linear regression was used. Preliminary results show that, across listening conditions, datasets and types of listeners, acoustic similarity models outperform cognitive models, thus suggesting a prominent role of sensory expectations in shaping neural responses to musical sounds. Potential neuronal mechanisms will be discussed, as well as the relationship of our findings with behavioral studies suggesting a preponderance of cognitive over sensory expectations during music listening.</p>
    </body>
    </html>
    