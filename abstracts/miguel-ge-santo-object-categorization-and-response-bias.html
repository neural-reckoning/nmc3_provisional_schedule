
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Object Categorization and Response Bias Flexibly Change Depending on Cross-Spatial Scale Coherence and Task Demands</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-29 12:15");</script>
            /
            Track 7
            /
            Interactive talk
            <div class="visible_at_time" data-start="2020-10-29 12:15" data-end="2020-10-29 12:30">
                <a href='https://www.youtube.com/watch?v=1gAtVTbcfiQ'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=1gAtVTbcfiQ'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Object Categorization and Response Bias Flexibly Change Depending on Cross-Spatial Scale Coherence and Task Demands</h1><h2>Miguel G.E. Santo</h2><h3>Miguel G. E. Santo; Johan Wagemans</h3><h2>Abstract</h1><p>Categorization of visual stimuli at different levels of abstraction relies on the encoding of relevant diagnostic features present at different spatial scales. We used the Eidolon Factory (Koenderink et al., 2017), an image-manipulation algorithm based on the scale-space representation of the early visual cortex that introduces random disarray fields across spatial scales. When the disarray is incoherent, edges become fuzzy and less defined; when it is coherent, the coarser scales dictate where the finer scales end up, leading to warping of the local structure of the image. With this method, we asked: is the brain using the global shape or is it detecting some salient feature to resolve a recognizable object? And, how is the correlational structure of different spatial scales interacting with the task demands? Images of animal faces, human faces and everyday objects were disarrayed coherently or incoherently to create a family of  50  eidolons per image with increasing disarray. Participants (N=217) viewed each family of eidolons in a smooth sequence from maximum disarray to none and performed a category verification task either at the superordinate (any face type) or basic (human face only) levels at different levels of uncertainty. In the first response, they used their gut feeling to respond, for the second response they had to be sure of their decision. When participants used their gut feeling to respond, we observed a basic-level advantage, but not an effect of the type of disarray. When they were sure of their response, we observed a superordinate advantage and stronger disarray effects in the coherent stimulus. Furthermore, participants changed their decision criterion depending on the abstraction level of the task. These results suggest that the visual system flexibly adjusts to the relevant perceptual information depending on task context and that it does not strictly adhere to feedforward processing.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    