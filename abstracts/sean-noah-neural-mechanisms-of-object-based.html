
    <!doctype html>

    <html lang="en">
    <head>
        <meta charset="utf-8">    
        <script type="text/JavaScript" src="https://MomentJS.com/downloads/moment.js"></script>
        <script type="text/JavaScript" src="https://momentjs.com/downloads/moment-timezone-with-data.min.js"></script>
        <title>Neural Mechanisms of Object-based Attention: Decoding EEG Alpha When Anticipating Faces, Scenes, and Tools</title>
        <style>
            
    * {
        font-family: "Trebuchet MS", Helvetica, sans-serif;
    }
    
        </style>
        <script type="text/JavaScript">
            
	function LT(t) {
        var m = moment.utc(t).tz(moment.tz.guess());
		document.write(m.format('MMMM Do YYYY, HH:mm z'));
	};
    function time_between(start, end) {
        var s = moment.utc(start);
        var e = moment.utc(end);
        var now = moment();
        return (s<=now) && (now<=e);
    };
    function update_visibility() {
        var now = moment();
        var elems = document.getElementsByClassName("visible_at_time");
        for(var i=0; i<elems.length; i++) {
            s = moment.utc(elems[i].dataset.start);
            e = moment.utc(elems[i].dataset.end);
            if ( (s<=now) && (now<=e) ) {
                elems[i].style.display = "block";
            } else {
                elems[i].style.display = "none";
            }
        }
    };
    setInterval(update_visibility, 60*1000);
    
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <h3>
            <a href="https://neuromatch.io">Neuromatch</a> 3 /
            <script type="text/JavaScript">LT("2020-10-30 17:30");</script>
            /
            Track 1
            /
            Traditional talk
            <div class="visible_at_time" data-start="2020-10-30 17:30" data-end="2020-10-30 17:45">
                <a href='https://www.youtube.com/watch?v=WOlN8NwDRmk'><i class="fa fa-youtube-play" style="font-size:24px;color:red"></i></a>
                <a href='https://www.youtube.com/watch?v=WOlN8NwDRmk'>Watch now on YouTube</a>
            </div>
        </h3>
        <h1>Neural Mechanisms of Object-based Attention: Decoding EEG Alpha When Anticipating Faces, Scenes, and Tools</h1><h2>Sean Noah</h2><h3>Travis Powell, UC Davis; Natalia Khodayari, Johns Hopkins; Diana Olivan, UC Davis; Mingzhou Ding, University of Florida; Ron Mangun, UC Davis</h3><h2>Abstract</h1><p>Attentional selection mechanisms in visual cortex involve changes in oscillatory neural activity in the electroencephalography (EEG) alpha band (8â€“12 Hz), with decreased alpha indicating focal enhancement of cortical activity and increased alpha indicating suppression of cortical activity. This pattern has been observed for spatial selective attention and attention to visual stimulus features such as color and motion. We investigated whether attention to categories of objects involves similar alpha-mediated changes in focal cortical excitability. In experiment 1, 20 volunteers (8 males; 12 females) were cued (80% predictive) on a trial-by-trial basis to anticipate different objects (faces, scenes, or tools). Support vector machine decoding of alpha power patterns revealed that late (>500 ms latency) in the cue-to-target foreperiod, EEG alpha differed with the to-be-attended object category, whereas patterns of the theta, beta, and gamma frequency bands were not systematically different across object conditions. In experiment 2, to control for the possibility that decoding of the physical features of cues led to our results, 25 participants (9 males; 16 females) performed a similar task as experiment 1, but with cues that were nonpredictive of the subsequently presented object category. Alpha decoding was now only significant in the early (<200 ms) foreperiod. In experiment 3, to control for the possibility that task set differences between the different object categories led to our experiment 1 results, 12 participants (5 males; 7 females) performed a predictive cuing task where the discrimination task for different objects was identical across object categories. The results replicated experiment 1. Together, these findings support the hypothesis that the neural mechanisms of visual selective attention involve focal cortical changes in alpha power not only for simple spatial and feature attention, but also for high-level object-based selection in humans.</p>
        <script type="text/JavaScript">
            update_visibility();
        </script>
    </body>
    </html>
    